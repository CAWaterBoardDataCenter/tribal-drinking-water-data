---
title: "Tribal Water Data Set Processing"
author: "Sam Prieto Serrano"
date: '2023-08-28'
output: 
  html_document: 
    toc: yes
    number_sections: yes
    theme: paper
    keep_html: yes
    highlight: textmate
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    eval = FALSE,
	message = FALSE,
	warning = FALSE,
	comment = FALSE
)
```

# Libraries

```{r load libraries}
library(shiny)
library(readxl)

# Mapping and GIS operations
library(sf)
library(leaflet)
library(htmlwidgets)

# shiny stuff
library(shinycssloaders)
library(DT)
library(shinyWidgets)
library(shinyjs)
library(here)
library(glue)

library(dplyr)
library(ggplot2)
library(plotly)
library(stringr)
library(tidyverse)
library(rlang)

# gpkg stuff
library(janitor)
library(esri2sf)
library(tigris)
```

# Overview

In this RMD/HTML file, I document part of work during summer 2023 on adding to the Tribal Data R Shiny tool at OIMA. The tasks included hear consist of two main types:

-   one in which I'm listing and cataloging the water data sets to be potentially included as sources within the tool,

-   and second in which I'm processing some of those data sets, as well as the land boundaries data sets from the Census Bureau and the Bureau of Indian Affairs

# Data set collection

In this section I will catalog the various data sources I came across and believed could add value to the tool.

As preface, the data sources that I was able to successfully add are processed in the next section [(2) Data set processing]. Other than those, the rest of these data sets proved troublesome to add during my fellowship time and I detail why this was.

## Already Included

The tool this summer was already working with a handful of data sets. You can read more details about the selection and processing of these in Alexis' 'tribal-data-exploration.rmd' file.

**Mobile home parks**

A list of mobile home / RV parks in California is available from the California Department of Housing and Community Development, at: <https://casas.hcd.ca.gov/casas/cmirMp/onlineQuery>.

**Wells - Combined Risks**

This data set categorizes by well type and risk level. The data set is available at: <https://gispublic.waterboards.ca.gov/portal/home/item.html?id=84dc4363570b42aba392952d8974c8ab>. Note that you have to then go to the "Water Quality Risk by Well (All Contaminants)" layer to get the well data.

**Small State Water Systems**

The data set is available at: <https://gispublic.waterboards.ca.gov/portal/home/item.html?id=2d34d39f75b8491d88adda57adb837ec&fromSearch=true&searchPosition=1&searchTerm=small%20state%20water%20systems>.

Next, there are the foundational data of the CA boundary and the LAR boundaries pulled from either Bureau of Indian Affairs or U.S. Census Bureau.

**U.S. Census Bureau**

For the boundaries from the U.S. Census Bureau the `tigris` R package was used to access the data set (with the function `tigris::native_areas()`).

**Bureau of Indian Affairs**

For the boundaries from the Bureau of Indian Affairs, as of September 2022, the data was only available via a REST service rather than CSV. The data set used in the app was pulled with the REST service. However, as of September 2023, there does not seem to be a working REST URL to pull updated data.

See more later in this document (at [New Version]).

## HWSS - Household Water Supply Shortage Reports

This section begins the list of data sets [newly gathered]{.underline} for the tool during summer 2023.

This data was added to the R Shiny app, and is processed in the [(2) Data set processing] section below.

Description: Statistics on reported dry wells are based on the Household Water Supply Shortage Reporting System Data. This data is visible at [this tool](https://gispublic.waterboards.ca.gov/portal/apps/webappviewer/index.html?id=70d27423735e45d6b037b7fbaea9a6a6) and can be pulled with REST API here: <https://services.arcgis.com/aa38u6OgfNoCkTJ6/ArcGIS/rest/services/Household_Water_Supply_Shortage_Reports/FeatureServer/0>.

Anna Holder also recommended this alternative source, which I did not get a chance to explore: <https://data.cnra.ca.gov/dataset/dry-well-reporting-system-data>.

## SAFER - SAFER Dashboard

This data was added to the R Shiny app, and is processed in the [(2) Data set processing] section below.

Description: "The Division of Drinking Water (DDW) identifies Failing and At-Risk community water systems and K-12 non-transient, non-community schools. This information is displayed online in the Safe and Affordable Funding for Equity and Resilience (SAFER) Dashboard. The data utilized for this assessment is derived from multiple sources: self-reported from water systems, data generated by DDW staff, other California state agencies, and U.S. Census. The data sources, calculation methods, Failing and At-Risk criteria, etc. are fully documented in the annual Drinking Water Needs Assessment report which is published annually on the State Water Board's website."

This data is visible and pulled from [the SAFER dashboard](https://www.waterboards.ca.gov/drinking_water/certlic/drinkingwater/saferdashboard.html) and can be found in CSV format here: <https://data.ca.gov/dataset/safer-failing-and-at-risk-drinking-water-systems>.

## FHAB - Freshwater Harmful Algae Bloom Reports

This data was added to the R Shiny app, and is processed in the [(2) Data set processing] section below.

Description: "Freshwater harmful algal bloom (HAB) data from the Freshwater Harmful Algal Bloom (FHAB) Reports database. The FHAB Reports database is the California State Water Resources Control Board's data system for data and information voluntarily reported through the Freshwater Incident Form found on the CA HABs Portal."

This data is accessing in CSV/REST API/JSON at [this link](https://data.ca.gov/dataset/surface-water-freshwater-harmful-algal-blooms/resource/c6f760be-b94f-495e-aa91-2d8e6f426e11#) which is <https://data.ca.gov/dataset/surface-water-freshwater-harmful-algal-blooms/resource/c6f760be-b94f-495e-aa91-2d8e6f426e11#>.

## Other Data

**GAMA Data**

This data is not currently included in the R Shiny app.

Description: "Groundwater quality data and related groundwater well information available on the page was queried from the GAMA Groundwater information system (GAMA GIS). Data provided represent a collection of groundwater quality results from various federal, state, and local groundwater sources. Results have been filtered to only represent untreated sampling results for the purpose of characterizing ambient conditions."

This data is available in CSV at [this link](https://catalog.data.gov/dataset/ground-water-water-quality-results) which is <https://catalog.data.gov/dataset/ground-water-water-quality-results>.

The issue has been getting the downloaded data to save as a .gpkg file (right now it just runs forever and does not 'write' the GPKG file). The thing that stands out about this data set is that it's over 10x larger than the other data sets I attempted, so it might be a size issue (or other obstacle in the formatting).

```{r GAMA csv to gpkg}
# # read data
# df_GAMA <- read_csv(here('gama_2023-07-03.csv'))
# 
# # convert to sf ---
# sf_GAMA <- st_as_sf(df_GAMA %>%
#                              filter(!is.na(as.numeric(gm_longitude)),
#                                     !is.na(as.numeric(gm_latitude))),
#                          coords = c('gm_longitude', 'gm_latitude')) %>%
#     st_set_crs(geographic_crs) %>%
#     st_transform(geographic_crs)
# 
# ## standardize field names ---
# sf_GAMA <- sf_GAMA %>%
#     clean_names()
# 
# # save as gpkg
# st_write(sf_GAMA, here('data_processed', 'new_GAMA_groundwaterquality.gpkg'))
```

**DWSL Data**

This data is not currently included in the R Shiny app. This is the California Water System Locations data.

Description: "This layer is a combination of data sources. California water systems are regulated and tracked differently based on system classification and and size, so a single layer data set for all drinking water systems in California was created in order to make consolidation and partnership outreach simpler."

This data is visible and in CSV format at [this tool](https://gispublic.waterboards.ca.gov/portal/apps/webappviewer/index.html?id=70d27423735e45d6b037b7fbaea9a6a6) and also available from REST API in geospatial format at <https://gispublic.waterboards.ca.gov/portal/home/item.html?id=346d649d1e654737ac5b6855466e89b2>.

Details on the issue:

1.  First issue: the CSV version of the file did not include Longitude/Latitude columns which meant I could not plot the items.
2.  Second issue: while I was able to use the REST API to get the data set as a GPKG, the 'st_filter' function (in the second code chunk below), that is needed to intersect the data with the LAR boundary data, crashed. Could not find a way to create the needed intersection.

Load the GPKG with REST URL:

```{r DWSL gpkg from REST}
# # setup 
# ## turn off scientific notation ---
# options(scipen = 999)
# 
# ## enter ArcGIS service URL ---
# service_url <- 'https://gispublic.waterboards.ca.gov/portalserver/rest/services/Hosted/California_Public_Water_System_Locations/FeatureServer/0'
# 
# ## enter name of output file (including extension - e.g., .shp, .gpkg)
# output_file_name <- 'new_drinking_water_system_locations.gpkg'
# 
# 
# # download data from ESRI service 
# gis_layer_data <- esri2sf(service_url)
# 
# 
# # clean data
# ## standardize field names ----
# gis_layer_data <- gis_layer_data %>% 
#     clean_names()
# 
# 
# 
# # write output file
# ## geopackage
# st_write(gis_layer_data, 
#          here('data_processed', 
#               output_file_name))
```

Run the intersect [fail]:

```{r make intersect of DWSL}
# # Read DWSL dataset
# ca_DWSL <- st_read(here('data_processed', 'new_drinking_water_system_locations.gpkg')) %>% 
#     st_transform(geographic_crs)
# 
# # filter for system locations in tribal boundaries
# DWSL_filtered <- st_filter(ca_DWSL, sf_tribal_boundaries)

# # join information about tribal area to filtered DWSL
# DWSL_filtered <- DWSL_filtered %>% st_join(sf_tribal_boundaries) %>% 
#     st_drop_geometry() 

```

**DWSA Data**

This data is not currently included in the R Shiny app. This is the California Water System Areas data.

Description: "Service area boundaries boundaries of drinking water service providers, as verified by the Division of Drinking Water, State Water Resources Control Board."

This feature layer is visible at [this link](https://gis.data.ca.gov/datasets/waterboards::california-drinking-water-system-area-boundaries/about) and also available from REST API at <https://gispublic.waterboards.ca.gov/portalserver/rest/services/Drinking_Water/California_Drinking_Water_System_Area_Boundaries/FeatureServer>. There is also this [other source](https://gispublic.waterboards.ca.gov/portal/home/item.html?id=fbba842bf134497c9d611ad506ec48cc) for the layer; it is unclear whether it is the same reports but possily more outdated.

Details on the issue:

1.  First issue: the CSV version of the file did not include Longitude/Latitude columns which meant I could not plot the items.
2.  Second issue: while I was able to use the REST API to get the data set as a GPKG, the subsequent code that I was using for "intersections" between data and the LAR boundaries did not work given that the System Area data is in *geopolygon* shape rather than *geopoint* shape. I'm sure there is a way of making this work (having points AND polygons) but I did not get a chance to integrate this.

Load the GPKG with REST URL:

```{r DWSA gpkg}
# ## esri2sf - see: https://github.com/yonghah/esri2sf
# # remotes::install_github('yonghah/esri2sf') # use this line to install package from github
# library(esri2sf)
# 
# 
# # setup ---
# ## turn off scientific notation ---
# options(scipen = 999)
# 
# ## enter ArcGIS service URL ---
# service_url <- 'https://gispublic.waterboards.ca.gov/portalserver/rest/services/Drinking_Water/California_Drinking_Water_System_Area_Boundaries/FeatureServer/0'
# 
# ## enter name of output file (including extension - e.g., .shp, .gpkg)
# output_file_name <- 'new_drinking_water_service_area.gpkg'
# 
# 
# # download data from ESRI service ---
# gis_layer_data <- esri2sf(service_url)
# 
# 
# # clean data ---
# ## standardize field names ----
# gis_layer_data <- gis_layer_data %>%
#     clean_names()
# 
# 
# # write output file ---
# # geopackage ---
# st_write(gis_layer_data,
#          here('data_processed',
#               output_file_name))
```

### Similar Issues

Similar to data above, the following two data sets consist of data in *geopolygon* shape, making them not work with the current code for intersecting with LARs.

**Groundwater Basin Boundaries**

This data is not currently included in the R Shiny app.

Description: "The dataset is a feature class showing the boundaries of 515 groundwater basins and subbasins as defined by the California Department of Water Resources as last modified by the Basin Boundary Emergency Regulation adopted on October 21, 2015 and subsequent modifications requested through the Basin Boundary Modification Request Process."

This data is visible at [this tool](https://gispublic.waterboards.ca.gov/portal/apps/webappviewer/index.html?id=70d27423735e45d6b037b7fbaea9a6a6) and also available from REST API at <https://gis.water.ca.gov/arcgis/rest/services/Geoscientific/i08_B118_SGMA_2019_Basin_Prioritization/FeatureServer/0>.

**Division of Drinking Water Area**

This data is not currently included in the R Shiny app.

Description: "This layer shows the five section areas of DDW's 24 Districts. This dataset's source is DDW's SDWIS contacts database."

This feature layer is visible at [this link](https://gispublic.waterboards.ca.gov/portal/home/item.html?id=c7e8cc11727149ab8e0b2974d7e1bc4d) and also available from REST API at <https://gispublic.waterboards.ca.gov/portalserver/rest/services/Hosted/SectionServiceAreaMap/FeatureServer>.

### Redundant Data

The following data sets provided data that was either already included in some part of another data set (i.e. SAFER), or would add updated version of data already added (i.e. SSWS).


**Small State Water Systems (SWSS)**

This data is not currently included in the R Shiny app. It has 2023 data for a data set added to the tool last year with 2022 data.

Description: "State small water system locations with water quality risk estimates (from 2023 Aquifer Risk Map) attached. "

This feature layer is visible at [this link](https://gispublic.waterboards.ca.gov/portal/home/item.html?id=f82374dc6c234d9d8911abac472e34ca).


**Bureau of Indian Affairs LAR Data**

As mentioned at [New Version], the previous sourcing of LAR data from BIA used by last year's fellow no longer is active. I believe any new attempt for updated BIA LAR data will have to come from their [OpenDataPortal](https://biamaps.geoplatform.gov/BIA-Opendata/).

For now, an alternative is the CSV format visible and accessible at [this tool](https://gispublic.waterboards.ca.gov/portal/apps/webappviewer/index.html?id=70d27423735e45d6b037b7fbaea9a6a6).

**CalEnviroScreen 4.0**

This data is not currently included in the R Shiny app. It has data included within the SAFER data set.

Description: "This layer shows the five section areas of DDW's 24 Districts. This dataset's source is DDW's SDWIS contacts database."

This feature layer ("water Wuality Risk") is visible at [this tool](https://gispublic.waterboards.ca.gov/portal/apps/webappviewer/index.html?id=17825b2b791d4004b547d316af7ac5cb) and also available from REST API at <https://services1.arcgis.com/PCHfdHz4GlDNAhBb/arcgis/rest/services/CalEnviroScreen_4_0_Results_/FeatureServer/0>.

# Data set processing

In this second section, I process the data that I was able to add to the tool. I use 'process' henceforth to refer to taking the data from whatever location I found it (a Waterboards tool, the CA Open Data Portal, etc) and saving the data into a geo-package format '.gpkg' that works within the R Shiny app.

For each data set below, I also 'run an intersect' with LAR data to make sure there is at least some relevant data that the data sets are adding to the tool (versus not having any data on LARs). These intersects are not saved; there are more-so a "trial run" of what goes on in the R Shiny code.

## GPKG of CA, Census, & BIA

These are the "foundational" data sets of the CA state boundary, and the LAR data sets from both the Bureau of Indian Affairs and the US Census Bureau.

#### Existing Version

Set default values and LAR data options.

```{r original defaults}
# The Leaflet package expects all point, line, and shape data to be specified in latitude and longitude using 
# WGS 84 (a.k.a. EPSG:4326). By default, when displaying this data it projects everything to EPSG:3857 and expects 
# that any map tiles are also displayed in EPSG:3857
# see: https://rstudio.github.io/leaflet/projections.html#:~:text=The%20Leaflet%20package%20expects%20all,also%20displayed%20in%20EPSG%3A3857

# Define coordinate systems to use for transformations
geographic_crs <- 4326 # see: https://epsg.io/4326
```

Get CA boundaries and zone in ("make valid") on tribal boundaries from selected data source out of two options.

```{r original boundaries load}
# read CA boundary 
sf_ca_boundary <- st_read(here('data_processed', 'ca_boundary.gpkg')) %>% 
    st_transform(geographic_crs)

# read data file, get the file name from list_tribal_data
sf_tribal_boundaries <- st_read(here('data_processed', 'native_areas_bia.gpkg')) %>% 
    st_transform(geographic_crs) %>% 
    st_make_valid(boundaries) # Fix geometries - otherwise 'invalid geometry' error

sf_tribal_boundaries2 <- st_read(here('data_processed', 'native_areas_census.gpkg')) %>% 
    st_transform(geographic_crs) %>% 
    st_make_valid(boundaries) # Fix geometries - otherwise 'invalid geometry' error
```

[*Comment*]{.underline}*: boundaries data includes some non-CA tribe LAR...*

#### New Version

Here I try to "create" my own copies of the LAR data sets from Census Bureau and BIA just like the previous fellow did (and which the tool currently runs on).

However, the URL used to pull from BIA does not work anymore and I could not find an alternative from BIA; so I'm going with the existing GPKGs for now.

```{r source census and bia data}
# crs_projected <- geographic_crs

# read CA 
# sf_california <- states(year = 2020, progress_bar = FALSE) %>% 
#     filter(STUSPS == 'CA') %>%
#     st_transform(crs_projected)

# URL link is broken now (09/2023), and did not find another source from BIA
# # read BIA
# sf_tribal_bia <- esri2sf(
#     url = 'https://biamaps.doi.gov/server/rest/services/DivLTR/BIA_AIAN_National_LAR/MapServer/0',
#     crs = NULL) %>%
#     rename(geom = geoms)
# 
# # filter for tribal areas in CA
# sf_tribal_bia <- sf_tribal_bia %>%
#     st_transform(crs_projected) %>%
#     st_filter(sf_california)

# st_write(sf_tribal_bia,
#          here('data_processed', 'native_areas_bia.gpkg'))
```

## SWSS Data

This is a data set already included in the tool, and here I am simply loading the GPKG and doing the intersection with tribal boundaries to create a pattern I follow with new data sets I will be adding.

This is what I refer to as 'the intersect' going forth; intersecting the selected water data file with the tribal boundaries data to find the water data that was recorded within LAR boundaries.

```{r original intersect of ssws}
# Read SSWS dataset
ca_SSWS <- st_read(here('data_processed', 'SSWS.gpkg')) %>% 
    st_transform(geographic_crs)

# filter for wells in tribal boundaries
SSWS_filtered <- st_filter(ca_SSWS, sf_tribal_boundaries)

# ---
# 'Bureau of Indian Affairs' = 'LARID' as id and 'LARNAME' as name
# 'Census Bureau' = 'AFFGEOID' as id and 'NAME' as name
# ---

# join information about tribal area to filtered SSWS
SSWS_filtered <- SSWS_filtered %>% st_join(sf_tribal_boundaries) %>% 
    st_drop_geometry() %>% select('system_nam', 'address', 'owner_type', 'phys_count', 
                  'wqrskbn', 'pwsid', 'service_co', 'population',
                  'svc_area_t', 'admin_cont', 'admin_emai', 'latitude', 
                  'longitude', 'LARNAME', 'LARID')

# map '0' to 'unknown' for water quality risk
SSWS_filtered["wqrskbn"][SSWS_filtered["wqrskbn"] == "0"] <- "unknown"
```

## HWSS Data

David processed the Household Water Supply Shortage file into a GPKG and shared the sample script with me. For testing, I attempt the script myself below

**Load the GPKG (like David did)**

The script is not running in my attempt, but will proceed with David's version of the file that he emailed me (and I added to the 'data_processed' folder).

```{r hwss csv to gpkg}
# ## esri2sf - see: https://github.com/yonghah/esri2sf
# # remotes::install_github('yonghah/esri2sf') # use this line to install package from github
# library(esri2sf)
# 
# 
# # setup ---
# ## turn off scientific notation ---
# options(scipen = 999)
# 
# ## enter ArcGIS service URL ---
# service_url <- 'https://services.arcgis.com/aa38u6OgfNoCkTJ6/ArcGIS/rest/services/Household_Water_Supply_Shortage_Reports/FeatureServer/0'
# 
# ## enter name of output file (including extension - e.g., .shp, .gpkg)
# output_file_name <- 'household_water_supply_shortage_reports.gpkg'
# 
# 
# # download data from ESRI service ---
# gis_layer_data <- esri2sf(service_url)
# 
# 
# # clean data ---
# ## standardize field names ---
# gis_layer_data <- gis_layer_data %>%
#     clean_names()
# 
# ## parse dates ---
# ## !!! NOTE: this may not always be needed with all layers !!!
# gis_layer_data <- gis_layer_data %>%
#     mutate(across(.cols = ends_with('_date'),
#                   .fns = ~ as_datetime(. / 1000 - 1) %>%
#                       as_date()
#                   )
#            )
# 
# 
# # write output file ---
# ## geopackage ---
# st_write(gis_layer_data,
#          here('data_processed',
#               output_file_name))
```

**Run the intersect**

This is exactly what I did with the SSWS data.

```{r intersect of hwss}
# Read HWSS dataset
ca_HWSS <- st_read(here('data_processed', 'new_household_water_supply_shortage_reports.gpkg')) %>% 
    st_transform(geographic_crs)

# filter for x in tribal boundaries
HWSS_filtered <- st_filter(ca_HWSS, sf_tribal_boundaries2)

# ---
# 'Bureau of Indian Affairs' = 'LARID' as id and 'LARNAME' as name
# 'Census Bureau' = 'AFFGEOID' as id and 'NAME' as name
# ---

# join information about tribal area to filtered SSWS
HWSS_filtered <- HWSS_filtered %>% st_join(sf_tribal_boundaries) %>% 
    st_drop_geometry() 

```

## SAFER Data

**Load the GPKG**

```{r SAFER csv to gpkg}
# read data
df_SAFER <- read_csv(here('SAFERDashboard_SourceData_Drinking_Water_Risk_Assessment.csv'))

# convert to sf ---
sf_SAFER <- st_as_sf(df_SAFER %>%
                             filter(!is.na(as.numeric(LONGITUDE)),
                                    !is.na(as.numeric(LATITUDE))),
                         coords = c('LONGITUDE', 'LATITUDE')) %>%
    st_set_crs(geographic_crs) %>%
    st_transform(geographic_crs)

## standardize field names ---
sf_SAFER <- sf_SAFER %>%
    clean_names()

# save as gpkg
# st_write(sf_SAFER, here('data_processed', 'new_SAFER_drinkingwatersystems.gpkg'))
```

**Run the intersect**

```{r make intersect of SAFER}
# Read SAFE dataset
ca_SAFER <- st_read(here('data_processed', 'new_SAFER_drinkingwatersystems.gpkg')) %>% 
    st_transform(geographic_crs)

# filter for x in tribal boundaries
SAFER_filtered <- st_filter(ca_SAFER, sf_tribal_boundaries)

# ---
# 'Bureau of Indian Affairs' = 'LARID' as id and 'LARNAME' as name
# 'Census Bureau' = 'AFFGEOID' as id and 'NAME' as name
# ---

# join information about tribal area to filtered SSWS
SAFER_filtered <- SAFER_filtered %>% st_join(sf_tribal_boundaries) %>% 
    st_drop_geometry() 

```

## FHAB Data

**Load the GPKG**

```{r FHAB csv to gpkg}
# read data
df_FHAB <- read_csv(here('FHABreports_fhab_bloomreport_portal.csv'))

# convert to sf ---
sf_FHAB <- st_as_sf(df_FHAB %>%
                             filter(!is.na(as.numeric(Longitude)),
                                    !is.na(as.numeric(Latitude))),
                         coords = c('Longitude', 'Latitude')) %>%
    st_set_crs(geographic_crs) %>%
    st_transform(geographic_crs)

## standardize field names ---
sf_FHAB <- sf_FHAB %>%
    clean_names()

# save as gpkg
# st_write(sf_FHAB, here('data_processed', 'new_FHAB_bloomreports.gpkg'))
```

**Run the intersect**

```{r make intersect of FHAB}
# Read SAFE dataset
ca_FHAB <- st_read(here('data_processed', 'new_FHAB_bloomreports.gpkg')) %>% 
    st_transform(geographic_crs)

# filter for x in tribal boundaries
FHAB_filtered <- st_filter(ca_FHAB, sf_tribal_boundaries2)

# ---
# 'Bureau of Indian Affairs' = 'LARID' as id and 'LARNAME' as name
# 'Census Bureau' = 'AFFGEOID' as id and 'NAME' as name
# ---

# join information about tribal area to filtered FHAB
FHAB_filtered <- FHAB_filtered %>% st_join(sf_tribal_boundaries2) %>% 
    st_drop_geometry() 

```

# Divide LAR data sets by status

Here I make use of the list I received '2023 02 01-Tribal Drinking Water Program Manager Assignments (1).xlsx' from Elizabeth to separate the LAR data entries between having federally regulated water systems, or not.

Load in the file of Tribes.

```{r load xl lib}
df_no_fed <- read_excel("C:/Users/sampr/OneDrive/Desktop/CWRCB_OIMA/Tribal Drinking Water Data/2023 02 01-Tribal Drinking Water Program Manager Assignments (1).xlsx", sheet=4)

df_no_fed <- df_no_fed[order(df_no_fed$`Federally recognized Tribes, no WS regulated by US EPA`, decreasing = FALSE), ]
```

Prep the two versions of the LAR data. Going forth below, all 'first' version of a boundary dataframe here is implied to correspond to the BIA version and the '2' or 'second' dataframe to the Census version.

```{r prep LAR data}
bound_prep <- sf_tribal_boundaries
bound_prep$LARNAME<-gsub(" LAR","",as.character(bound_prep$LARNAME))

bound_prep2 <- sf_tribal_boundaries2[order(sf_tribal_boundaries2$NAMELSAD, decreasing = FALSE), ]
rownames(bound_prep2) <- NULL
```

First, I attempted to separate them by using some code and filtering functions. However, this method was not working well because the three lists have different versions of each LAR name (e.g. *Death Valley Timbi-Sha Shoshone Band of California* vs *Timbisha Shoshone*).

This made it too hard to do a parse/match function in code. Using any text matching/edit distance measurement between the names added uncertainty that I chose not to add to the process.

```{r failed split}
# bound_prep <- sf_tribal_boundaries
# bound_prep$LARNAME<-gsub(" LAR","",as.character(bound_prep$LARNAME))
# 
# bound_prep2 <- sf_tribal_boundaries2[order(sf_tribal_boundaries2$NAMELSAD, decreasing = FALSE), ]
# rownames(bound_prep2) <- NULL

# library(stringdist)

#df_no_fed_c <- c(df_no_fed$`Federally recognized Tribes, no WS regulated by US EPA`)
# 
# boundaries_no_fed <- bound_prep[amatch(df_no_fed_c, bound_prep$NAMELSAD, maxDist = 20),]
# # bound_prep2$STATUS = if_else(sum(str_detect(bound_prep2$NAME, df_no_fed$`Federally recognized Tribes, no WS regulated by US EPA`)) > 0, "yes_fed", "no_fed")

```

## Manual Method

Instead of using code, I resorted to saving all three lists of names to one CSV, and manually reading through all to identify matches. This allowed me to make the exact row vectors and sub-selecting those rows myself. I will be sharing this CSV with the delivery of this RMD file.

```{r split LAR by status}
# alphabetize the relevant column of the df
bound_prep <- sf_tribal_boundaries[order(sf_tribal_boundaries$LARNAME, decreasing = FALSE), ]
rownames(bound_prep) <- NULL

# make a row vector of rows manually verified to be on the "not fed regulated WS" list
c_rows1 <- c(1, 7, 8, 9, 14, 15, 17, 20, 21, 23, 25, 41, 43, 46, 48, 49, 53, 55, 57, 59, 61, 63, 65, 71, 72, 73, 74, 80, 81, 84, 88, 90, 94, 96, 101, 106, 108, 109, 110)

bound_prep$fed_regulated = "yes"
bound_prep[c_rows1, "fed_regulated"] = "no"

# alphabetize the relevant column of the df
bound_prep2 <- sf_tribal_boundaries2[order(sf_tribal_boundaries2$NAMELSAD, decreasing = FALSE), ]
rownames(bound_prep2) <- NULL

c_rows2 <- c(1, 7, 8, 9, 14, 15, 16, 19, 20, 22, 36, 38, 41, 42, 44, 45, 49, 51, 55, 56, 57, 58, 60, 62, 68, 69, 70, 71, 77, 78, 82, 86, 90, 92, 98, 103, 107)

bound_prep2$fed_regulated = "yes"
bound_prep2[c_rows2, "fed_regulated"] = "no"
```

Now I will save these four file versions to be used in the tool.

```{r save versions}
# bound_prep %>% filter(fed_regulated == "no") %>%
#     st_write(here('data_processed', 'notfed_native_areas_bia.gpkg'))
# 
# bound_prep %>% filter(fed_regulated == "yes") %>%
#     st_write(here('data_processed', 'yesfed_native_areas_bia.gpkg'))
# 
# bound_prep2 %>% filter(fed_regulated == "no") %>%
#     st_write(here('data_processed', 'notfed_native_areas_census.gpkg'))
# 
# bound_prep2 %>% filter(fed_regulated == "yes") %>%
#     st_write(here('data_processed', 'yesfed_native_areas_census.gpkg'))
```

## Find Unmatched Tribes

Here I make a list of Tribes I received on the '2023 02 01-Tribal Drinking Water Program Manager Assignments (1).xlsx' file, but did not find a corresponding LAR boundary data point in either the Census or BIA data sets.

In other words, this is the list of tribes that did not have a LAR boundary according to BIA or Census Bureau data despite being in the list of federally recognized Tribes sent over by Elizabeth.

One important note is that the Census list has only *Pit River Trust Land*, while the other lists include multiple with this pre-name (e.g. *Pit River Tribe-Big Bend Rancheria* and *Pit River Tribe-Burney Tract*).

```{r make unmatched csv}
df_no_fed_t <- df_no_fed[c(7, 9, 11, 22, 23, 32, 33, 46),]
colnames(df_no_fed_t) <- c("Federally recognized Tribes, no WS regulated by US EPA, not on Census or BIA data")

# write.csv(df_no_fed_t, "09252023_Tribes not on Census or BIA LAR data.csv", row.names=FALSE)
```

# Future

In this final section, I will detail relevant information for moving forward and a summary of challenges.

## Next Steps

Here I list some questions for the next on-hands person that tried to debug and expand the tool.

1.  Within the app code, there is two different ways in which "intersections" between the LAR boundaries and the select water data sets are created. You will see that the Mobile Home Parks uses sf_ca_mhp() and SSWS uses intersectingSSWS(). I never cleared up the purpose or reason for different intersecting method, and thus my three added data sets used both.
2.  Circle back with OPP and team on whether it is still valuable to have mobile home parks as a tab. If removed, beware of the unique code that tab1 has, and make sure to keep that for your new 'tab1'.

And a list of ideas or things to do.

1.  Determine what columns of the water data sets are important to subselect and to display in the pop-overs.
2.  Clean up the reactivity from table and barchart clicks to data table. Currently reactivity is only from map LARs to data table.
3.  Meet with OPP about exact reporting needed and inform the filters. Potential ideas: [Dropdowns Github](https://github.com/psimm/dropdowns), [Select checkbox](https://shiny.posit.co/r/reference/shiny/1.7.4/selectinput), [Dependent select](https://heds.nz/posts/dependent-selectInputs-shiny/).
4.  Discuss the benefit of including both BIA and Census (and/or other) sources of LAR boundaries. Any changes?

## "No" LAR Data Crashing

Currently, both "no" versions of the tribal boundaries data sets ('notfed_native_areas_census.gpkg' and 'notfed_native_areas_bia.gpkg') lead the tool to crash when selected from the dropdown menu as the tribal boundaries to apply.

*As a reminder, 'notfed' refers to tribal LARs that have no federally regulated water systems.*

Attempting to troubleshoot, here I read them in specifically and tried some code sections from the app to try to identify the error.

```{r load test boundaries}
# read CA boundary 
sf_ca_boundary <- st_read(here('data_processed', 'ca_boundary.gpkg')) %>% 
    st_transform(geographic_crs)

# read data file, get the file name from list_tribal_data
sf_tribal_boundaries_yes <- st_read(here('data_processed', 'yesfed_native_areas_bia.gpkg')) %>% 
    st_transform(geographic_crs) %>% 
    st_make_valid(boundaries) # Fix geometries - otherwise 'invalid geometry' error

sf_tribal_boundaries_no <- st_read(here('data_processed', 'notfed_native_areas_census.gpkg')) %>% 
    st_transform(geographic_crs) %>% 
    st_make_valid(boundaries) # Fix geometries - otherwise 'invalid geometry' error
```

It seems that the issue stems from the fact that these "no" LAR data sets, when intersected with the other water data (SSWS, Wells, etc), result in an intersection of none. In other words, a lot of the time our water data sets have no data that lies within these tribal LARs with no federally regulated water (which seems logical).

However, the original versions of the BIA and Census LAR data sets (with and without federally-regulated water) would sometimes lead to a intersection of none, and yet that would not cause the app to crash. Thus, I believe the issue was that these empty intersections from the "No" versions were not correctly formatted.

Confirming my thought, I found formatting was in fact different. These problematic empty intersections displayed as "No data available" when loaded in R, rather than a valid data frame with empty values. In the code chunk below, I add some if/else conditional statements to catch an empty intersection and formatting it so that it does not say "No data available".

```{r again intersect of ssws}
# Read SSWS dataset
ca_SSWS <- st_read(here('data_processed', 'SSWS.gpkg')) %>% 
    st_transform(geographic_crs)

# filter for wells in tribal boundaries
SSWS_filtered <- st_filter(ca_SSWS, sf_tribal_boundaries_no)

# ---
# 'Bureau of Indian Affairs' = 'LARID' as id and 'LARNAME' as name
# 'Census Bureau' = 'AFFGEOID' as id and 'NAME' as name
# ---

# join information about tribal area to filtered SSWS
SSWS_filtered <- SSWS_filtered %>% st_join(sf_tribal_boundaries_no) %>% 
    st_drop_geometry() 

SSWS_filtered <- if (nrow(SSWS_filtered) > 0) {select(SSWS_filtered, 'system_nam', 'address', 'owner_type', 'phys_count', 'wqrskbn', 'pwsid', 'service_co', 'population',
                  'svc_area_t', 'admin_cont', 'admin_emai', 'latitude', 
                  'longitude', 'LARNAME', 'LARID')} else {SSWS_filtered}

if (nrow(SSWS_filtered) == 0){
    SSWS_filtered[1, ] <- c(NA)
}
# map '0' to 'unknown' for water quality risk
SSWS_filtered["wqrskbn"][SSWS_filtered["wqrskbn"] == "0"] <- "unknown"
```

Sadly, while this work, the "No" LAR data sets still crash the app. I still predict the resulting "empty" intersections are not liked by some other part of the app.

## Misc Steps

The steps below were not completed and might not be correct.

**Compile universal tribal LAR list**

For the purposes of the dropdown menu feature, I need to compile a list of all LAR names that could be an option for a user, from both Census and BIA data sets. Unfortunately, I could not get the list automatically because the server side of things (user input, and choice of LAR data set) are not accessible in the UI set up.

```{r compile name list}
# colnames(bound_prep)[3] <- "NAMELSAD"
# binded_boundaries <- bind_rows(bound_prep, bound_prep2) %>% select('NAMELSAD')
# 
# df_new <- binded_boundaries[!duplicated(binded_boundaries), ]
# df_new <- binded_boundaries[order(binded_boundaries$NAMELSAD), ]

```
